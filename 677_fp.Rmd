---
title: "677_fp"
author: "Samuel"
date: "May 7, 2019"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#1 Statistics and the Law
```{r}
library(tidyverse)
library(readr)
library(dplyr)
library(pwr)
library(fitdistrplus)
library(MASS)


acorn <- read_csv("acorn.csv")
test1 <- t.test(acorn$MIN, acorn$WHITE, paired = T)
test1$p.value

#According to the p-value, the refusal rate for minority applicants is significantly different from the refusal rate for white applicants which warrants a corrective action.

#Further Analysis, Sufficient for this dataset.
#power analysis
##Settings
pa <- cbind(NULL)
n <- seq(2, 50, by = 1)
##Loop
for (i in n) {
  papwr <- pwr.t2n.test(
    n1 = i, n2 = i,
    sig.level = 0.05, power = NULL,
    d = abs(mean(acorn$MIN)-mean(acorn$WHITE))/sd(acorn$MIN), alternative = "two.sided"
  )
  pa <- rbind(pa, papwr$power)
}

pa <- as.data.frame(pa)

ggplot(pa) + geom_line(aes(x = n, y = V1, color = "salmon")) + scale_color_discrete(name = "Effect_size", labels = c(abs(mean(acorn$MIN)-mean(acorn$WHITE))/sd(acorn$MIN))) + geom_hline(yintercept = 0.8, color = "gray") + scale_y_continuous(breaks = seq(0, 1, by = 0.1)) + xlab("Sample_size") + ylab("PowerRate")


```

According to the power plot, the sample size that needed to reach 80% power rate is around 7, but we have total of 20 sample size in the acorn dataset, which means that it is sufficient.

#2 Comparing supplies
```{r}
#H0:All schools have the same quality
#H1:All schools have the different quality

product <- matrix(c(12,23,89,8,12,62,21,30,119), byrow=TRUE, ncol=3, nrow = 3)
colnames(product) <- c("dead","art","fly")
product <- as.data.frame(product)
product$schname[1] <- "Area51" 
product$schname[2] <- "BDV" 
product$schname[3] <- "Giffen" 
chisq.test(product[,1:3],correct = F)

```

According to the Chi-squared test, this p-value is 0.8613 which is not significant. Thus, we fail to reject the null hypothesis that all schools have the same quality.

#3 How deadly are sharks?
```{r}
shark <- read_csv("sharkattack.csv")
shark_US <- shark[which(shark$`Country code` == "US"),]
shark_AU <- shark[which(shark$`Country code`== "AU"),]
shark_new <- rbind(shark_US, shark_AU)
shark_new$X1 <- NULL

fatal_count <- shark_new %>% group_by(shark_new$`Country code`, shark_new$Fatal) %>% summarize(count = n())

fatal_count <- fatal_count[-which(fatal_count$`shark_new$Fatal` == "UNKNOWN"), ]
fatal_count

fatal_count_N <- fatal_count[which(fatal_count$`shark_new$Fatal` == "N"),]
fatal_count_Y <- fatal_count[which(fatal_count$`shark_new$Fatal` == "Y"),]
fatal_count <- left_join(fatal_count_N, fatal_count_Y, by = "shark_new$`Country code`")
fatal_count$total <- fatal_count$count.x + fatal_count$count.y
fatal_count$fatal_percentage <- fatal_count$count.y/ fatal_count$total
colnames(fatal_count) <- c("countrycode", "Non_Fatal", "Non_Fatal_count", "Fatal", "Fatal_count", "total_count","Fatal_percentage")
fatal_count$Non_Fatal <- NULL
fatal_count$Fatal <- NULL
fatal_count
```

From this table, we could see that although the number of shark attack reports in US is more than that in Austrilia, the percentage of fatal attack in Austrilia is much more than percentage of fatal attack in US.

#4 power analysis

Since the books says the power that detects for the difference between hypothetical parameters .65 and .45 is .48 and the power that detects for the difference between hypothetical parameters .25 and .05 is .82. However, the difference between both pairs of values is .20. It means that hypothetical parameters of this binomial distribution doesn not provide a scale of equal units of detectability.On the other hand, when using arcsine transformation, it transforms the scale of proportional parameter to the scale from −π/2 to π/2. In addition, t1 -t2 = h, which provode a scale of euqal dectectability. Thus, it is a solution to solve the problem that does not provide of equal units of detectability.

#5 Estimators

###Exponential

See the answer in Knitted PDF

###A new distribution

See the answer in Knitted PDF

####Rain in Southern Illinois
```{r}
rain60 <- read.table("ill-60.txt")
rain61 <- read.table("ill-61.txt")
rain62 <- read.table("ill-62.txt")
rain63 <- read.table("ill-63.txt") 
rain64 <- read.table("ill-64.txt")
              
rain60 <- as.numeric(as.array(rain60$V1))
rain61 <- as.numeric(as.array(rain61$V1))
rain62 <- as.numeric(as.array(rain62$V1))
rain63 <- as.numeric(as.array(rain63$V1))
rain64 <- as.numeric(as.array(rain64$V1))

plotdist(rain60)
plotdist(rain61)
plotdist(rain62)
plotdist(rain63)
plotdist(rain64)

totalrain <- as.data.frame(t(c(sum(rain60),sum(rain61),sum(rain62),sum(rain63),sum(rain64))))
colnames(totalrain)<-c("Total1960","Total1961","Total1962","Total1963","Total1964")
#1961 has the most rainfall, and then the rainfall decreases each year. Until 1964, the rainfall become the least.

#Gamma distribution
rain01234 <- c(rain60,rain61,rain62,rain63,rain64)
raingamma <- fitdist(rain01234, "gamma")
plot(raingamma)
#Based on the plot, I am agree that gamma distribution fits well. From Q-Q plot, we could see most of the points are distributed near the line. 

rainmom <- fitdist(rain01234, "gamma",method = "mme")
rainmle <- fitdist(rain01234, "gamma",method = "mle")
bootmom <- bootdist(rainmom)
bootmle <- bootdist(rainmle)
summary(bootmom)
summary(bootmle)

#We can see for bootstrap, the 95% CI interval is (0.28,0.52) as well as rate is (1.19,2.56). On the other hand, for MLE, the 95% CI interval is (0.38,0.52) as well as rate is (1.56,2.55).In this case, I would prefer MLE as my estimator since it has a smaller CI interval result in a lower variance

```


#6 Analysis of decision theory article

See the answer in Knitted PDF